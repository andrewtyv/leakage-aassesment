{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefaffb4-fd84-4abb-82b7-7763e07b0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87580d2e-ea05-45c5-a68a-7a86b486f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_traces_sorted(traces_path: str) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Return a list of trace files sorted by their numeric index in 'trace_<idx>.txt'.\n",
    "    Accepts absolute or relative path.\n",
    "    \"\"\"\n",
    "    paths = [Path(p) for p in glob.glob(str(Path(traces_path) / \"trace_*.txt\"))]\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No trace_*.txt files under: {traces_path}\")\n",
    "    # extract numeric index\n",
    "    def idx(p: Path) -> int:\n",
    "        m = re.match(r\"trace_(\\d+)\\.txt$\", p.name)\n",
    "        if not m:\n",
    "            raise ValueError(f\"Bad trace filename: {p.name}\")\n",
    "        return int(m.group(1))\n",
    "    paths.sort(key=idx)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274fca96-079d-497d-ac71-fef2d79a1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inputs_matrix(inputs_file: str, ncols: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load 'inputs.txt' as numeric matrix with ncols columns (default 7: V1..V7).\n",
    "    Assumes space-separated values with no header.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(inputs_file, sep=r\"\\s+\", header=None, engine=\"python\")\n",
    "    if df.shape[1] != ncols:\n",
    "        raise ValueError(f\"Expected {ncols} columns, got {df.shape[1]} in {inputs_file}\")\n",
    "    return df.values  # (N, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ea2c29-d1b3-4c8c-88ab-02273e263920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_traces_matrix(traces_path: str) -> Tuple[np.ndarray, List[int]]:\n",
    "    \"\"\"\n",
    "    Read all traces into a matrix of shape (N, S).\n",
    "    Returns (traces, idx_list), where idx_list contains the numeric file indices (0-based).\n",
    "    \"\"\"\n",
    "    files = list_traces_sorted(traces_path)\n",
    "    idx_list = []\n",
    "    rows = []\n",
    "    for f in files:\n",
    "        m = re.match(r\"trace_(\\d+)\\.txt$\", f.name)\n",
    "        idx_list.append(int(m.group(1)))\n",
    "        # robust read: allow whitespace/newlines; each file is 1D vector\n",
    "        data = np.loadtxt(f, dtype=float)\n",
    "        rows.append(np.atleast_1d(data))\n",
    "    # sanity: ensure equal length (pad/raise if needed)\n",
    "    lens = [r.size for r in rows]\n",
    "    if len(set(lens)) != 1:\n",
    "        raise ValueError(f\"Traces have varying lengths: {set(lens)}\")\n",
    "    X = np.vstack(rows)  # (N, S)\n",
    "    return X, idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa412066-517f-40cb-9b81-f84afcc6cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_inputs_to_traces(inputs: np.ndarray, idx_list: List[int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Align inputs rows to trace files by 0-based index in filename.\n",
    "    \"\"\"\n",
    "    max_idx = max(idx_list)\n",
    "    if max_idx >= inputs.shape[0]:\n",
    "        raise IndexError(\n",
    "            f\"inputs has only {inputs.shape[0]} rows, but file index {max_idx} appears.\"\n",
    "        )\n",
    "    aligned = inputs[np.array(idx_list), :]  # pick rows by 0-based indices\n",
    "    return aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae3e213-1625-4549-8665-52679819b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_traces(X: np.ndarray, qs: int, qe: Optional[int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Slice columns [qs:qe] (1-based inclusive in your R; here we accept 1-based for familiarity).\n",
    "    If qe is None, use full width. Returns a copy.\n",
    "    \"\"\"\n",
    "    S = X.shape[1]\n",
    "    if qe is None:\n",
    "        qe = S\n",
    "    # convert to 0-based python slicing\n",
    "    qs0 = max(0, qs - 1)\n",
    "    qe0 = min(S, qe)  # slice end is exclusive in Python, so keep as is\n",
    "    if qs0 >= qe0:\n",
    "        raise ValueError(f\"Bad window [{qs}, {qe}] for S={S}\")\n",
    "    return X[:, qs0:qe0].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcde97e4-68b4-465c-9844-f4ca570d62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fixed_random(\n",
    "    inputs_aligned: np.ndarray,\n",
    "    v: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Return (fixed_rows, random_rows) as arrays of row indices based on V1 == v criterion.\n",
    "    \"\"\"\n",
    "    V1 = inputs_aligned[:, 0]\n",
    "    fixed_rows = np.where(V1 == v)[0]\n",
    "    random_rows = np.where(V1 != v)[0]\n",
    "    if fixed_rows.size == 0 or random_rows.size == 0:\n",
    "        raise ValueError(\"One of the groups is empty (fixed_rows or random_rows).\")\n",
    "    return fixed_rows, random_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10fb9788-29dd-4132-8af5-6e3e8ce95adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_groups(\n",
    "    X: np.ndarray, fixed_rows: np.ndarray, random_rows: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build group matrices (fixed, random) by selecting corresponding rows.\n",
    "    \"\"\"\n",
    "    fixed = X[fixed_rows, :]\n",
    "    random = X[random_rows, :]\n",
    "    return fixed, random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8bb3958-a59c-4aa7-ada2-fff97e53da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvla_welch_tcurve(fixed: np.ndarray, random: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute per-sample Welch's t-statistic (column-wise).\n",
    "    Returns (S,) array of t-values.\n",
    "    \"\"\"\n",
    "    if fixed.shape[1] != random.shape[1]:\n",
    "        raise ValueError(\"fixed and random must have same number of columns\")\n",
    "    S = fixed.shape[1]\n",
    "    tvals = np.empty(S, dtype=float)\n",
    "    for i in range(S):\n",
    "        t = stats.ttest_ind(fixed[:, i], random[:, i], equal_var=False, nan_policy=\"omit\")\n",
    "        tvals[i] = t.statistic\n",
    "    return tvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7247faa5-1e61-4804-a8c8-61f9a7b7f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ksla_curve(fixed: np.ndarray, random: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute per-sample two-sample KS statistic (D) column-wise.\n",
    "    Returns (S,) array of KS D-values in [0,1].\n",
    "    \"\"\"\n",
    "    if fixed.shape[1] != random.shape[1]:\n",
    "        raise ValueError(\"fixed and random must have same number of columns\")\n",
    "    S = fixed.shape[1]\n",
    "    dvals = np.empty(S, dtype=float)\n",
    "    for i in range(S):\n",
    "        d = stats.ks_2samp(fixed[:, i], random[:, i], alternative=\"two-sided\", method=\"auto\")\n",
    "        dvals[i] = d.statistic\n",
    "    return dvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf153e1-45d0-4df5-96f9-a0481977bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvla_power_curve(\n",
    "    fixed: np.ndarray,\n",
    "    random: np.ndarray,\n",
    "    min_fixed: int = 10,\n",
    "    max_steps: int = 100,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute 'power curve':\n",
    "    for increasing m (traces per group), compute max |t| over all samples using first m traces.\n",
    "    Returns (m_values, max_abs_t_per_m).\n",
    "    \"\"\"\n",
    "    m_max = min(fixed.shape[0], random.shape[0])\n",
    "    if m_max < min_fixed:\n",
    "        raise ValueError(\"Not enough traces per group for power curve.\")\n",
    "    # choose up to max_steps m-values from [min_fixed..m_max]\n",
    "    ms = np.unique(np.round(np.linspace(min_fixed, m_max, num=min(max_steps, m_max - min_fixed + 1)))).astype(int)\n",
    "    out = np.empty(ms.size, dtype=float)\n",
    "    for j, m in enumerate(ms):\n",
    "        tvals = tvla_welch_tcurve(fixed[:m, :], random[:m, :])\n",
    "        out[j] = np.nanmax(np.abs(tvals))\n",
    "    return ms, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3473320-18ac-4b4d-855e-5de1b796787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tvla_curve(\n",
    "    tvals: np.ndarray,\n",
    "    qs: int,\n",
    "    qe: int,\n",
    "    threshold: float = 4.5,\n",
    "    title: str = \"TVLA (Welch)\",\n",
    "    figsize: Tuple[float, float] = (10, 4),\n",
    "    out_pdf: Optional[str] = None,\n",
    ") -> None:\n",
    "    x = np.arange(qs, qs + tvals.size)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(x, tvals, lw=1.3)\n",
    "    plt.axhline(+threshold, color=\"r\", ls=\"--\")\n",
    "    plt.axhline(-threshold, color=\"r\", ls=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(f\"Sample index ({qs}-{qe})\")\n",
    "    plt.ylabel(\"t-value\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if out_pdf:\n",
    "        plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc83c39f-9c0f-4417-8b40-a8c9f11f0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ksla_curve(\n",
    "    dvals: np.ndarray,\n",
    "    qs: int,\n",
    "    qe: int,\n",
    "    threshold: Optional[float] = None,\n",
    "    title: str = \"KSLA (KS statistic)\",\n",
    "    figsize: Tuple[float, float] = (10, 4),\n",
    "    out_pdf: Optional[str] = None,\n",
    ") -> None:\n",
    "    x = np.arange(qs, qs + dvals.size)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(x, dvals, lw=1.3, color=\"darkgreen\")\n",
    "    if threshold is not None:\n",
    "        plt.axhline(threshold, color=\"r\", ls=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(f\"Sample index ({qs}-{qe})\")\n",
    "    plt.ylabel(\"KS D\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if out_pdf:\n",
    "        plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1e672e-98df-45f2-9014-2d30cdd9939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_power_curve(\n",
    "    m_values: np.ndarray,\n",
    "    max_abs_t: np.ndarray,\n",
    "    title: str = \"TVLA max-|t| vs traces-per-group\",\n",
    "    figsize: Tuple[float, float] = (10, 4),\n",
    "    out_pdf: Optional[str] = None,\n",
    ") -> None:\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(m_values, max_abs_t, width=max(1, int(len(m_values) / 40)))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Traces per group (m)\")\n",
    "    plt.ylabel(\"Max |t| across window\")\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    if out_pdf:\n",
    "        plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f08cf2-1374-492b-bf9f-5e4befd265f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tvla_pipeline(\n",
    "    name: str,\n",
    "    traces_path: str,\n",
    "    inputs_file: str,\n",
    "    v: float = 0.5,\n",
    "    qs: int = 1,\n",
    "    qe: Optional[int] = None,\n",
    "    tvla_threshold: float = 4.5,\n",
    "    min_fixed: int = 10,\n",
    "    out_dir: str = \"./out_tvla\",\n",
    "    save_plots: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    End-to-end TVLA like your R function:\n",
    "    1) load traces and inputs, align by numeric index\n",
    "    2) select window [qs:qe]\n",
    "    3) split into fixed vs random by V1==v\n",
    "    4) compute Welch t-curve\n",
    "    5) save plot/csv\n",
    "    6) compute power curve and save\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    # load / align\n",
    "    X, idx_list = load_traces_matrix(traces_path)\n",
    "    inputs = load_inputs_matrix(inputs_file, ncols=7)\n",
    "    inputs_aligned = align_inputs_to_traces(inputs, idx_list)\n",
    "    # window\n",
    "    Xw = window_traces(X, qs, qe)\n",
    "    S = Xw.shape[1]\n",
    "    if qe is None:  # for labeling\n",
    "        qe = qs + S - 1\n",
    "    # split\n",
    "    fixed_rows, random_rows = split_fixed_random(inputs_aligned, v)\n",
    "    fixed, random = extract_groups(Xw, fixed_rows, random_rows)\n",
    "    # t-curve\n",
    "    tvals = tvla_welch_tcurve(fixed, random)\n",
    "    # save t-curve CSV\n",
    "    t_csv = str(Path(out_dir) / f\"tvalues_{name}.csv\")\n",
    "    pd.DataFrame({\"sample\": np.arange(qs, qs + S), \"t_value\": tvals}).to_csv(t_csv, index=False)\n",
    "    # plot t-curve\n",
    "    t_pdf = str(Path(out_dir) / f\"tvla_{name}.pdf\")\n",
    "    if save_plots:\n",
    "        plot_tvla_curve(tvals, qs, qe, threshold=tvla_threshold, title=f\"TVLA — {name}\", out_pdf=t_pdf)\n",
    "    # leakage points\n",
    "    leaks = np.where(np.abs(tvals) > tvla_threshold)[0]\n",
    "    # power curve\n",
    "    #m_vals, max_abs_t = tvla_power_curve(fixed, random, min_fixed=min_fixed, max_steps=100)\n",
    "    #p_csv = str(Path(out_dir) / f\"tvla_power_curve_{name}.csv\")\n",
    "    #pd.DataFrame({\"traces_per_group\": m_vals, \"max_abs_t\": max_abs_t}).to_csv(p_csv, index=False)\n",
    "    #p_pdf = str(Path(out_dir) / f\"tvla_power_curve_{name}.pdf\")\n",
    "    #if save_plots:\n",
    "     #   plot_power_curve(m_vals, max_abs_t, title=f\"TVLA power curve — {name}\", out_pdf=p_pdf)\n",
    "\n",
    "    return dict(\n",
    "        name=name,\n",
    "        t_values=tvals,\n",
    "        leakage_points=(leaks + qs),  # back to 1-based labeling of sample index\n",
    "        fixed_count=fixed.shape[0],\n",
    "        random_count=random.shape[0],\n",
    "        window=(qs, qe),\n",
    "        csv_tvalues=t_csv,\n",
    "        pdf_tvalues=t_pdf if save_plots else None,\n",
    "        #csv_power=p_csv,\n",
    "\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "870e6924-56ed-4915-8019-607ceb454172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ksla_pipeline(\n",
    "    name: str,\n",
    "    traces_path: str,\n",
    "    inputs_file: str,\n",
    "    v: float = 0.5,\n",
    "    qs: int = 1,\n",
    "    qe: Optional[int] = None,\n",
    "    ks_threshold: Optional[float] = None,   # if None, no horizontal line\n",
    "    out_dir: str = \"./out_tvla\",\n",
    "    save_plots: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Mirror of TVLA driver but computing KS curve (for convenience).\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    # load / align / window\n",
    "    X, idx_list = load_traces_matrix(traces_path)\n",
    "    inputs = load_inputs_matrix(inputs_file, ncols=7)\n",
    "    inputs_aligned = align_inputs_to_traces(inputs, idx_list)\n",
    "    Xw = window_traces(X, qs, qe)\n",
    "    S = Xw.shape[1]\n",
    "    if qe is None:\n",
    "        qe = qs + S - 1\n",
    "    # split groups\n",
    "    fixed_rows, random_rows = split_fixed_random(inputs_aligned, v)\n",
    "    fixed, random = extract_groups(Xw, fixed_rows, random_rows)\n",
    "    # ks curve\n",
    "    dvals = ksla_curve(fixed, random)\n",
    "    # save CSV\n",
    "    ks_csv = str(Path(out_dir) / f\"ksla_values_{name}.csv\")\n",
    "    pd.DataFrame({\"sample\": np.arange(qs, qs + S), \"ks\": dvals}).to_csv(ks_csv, index=False)\n",
    "    # plot\n",
    "    ks_pdf = str(Path(out_dir) / f\"ksla_{name}.pdf\")\n",
    "    if save_plots:\n",
    "        plot_ksla_curve(dvals, qs, qe, threshold=ks_threshold, title=f\"KSLA — {name}\", out_pdf=ks_pdf)\n",
    "\n",
    "    leaks = None\n",
    "    if ks_threshold is not None:\n",
    "        leaks = (np.where(dvals > ks_threshold)[0] + qs)\n",
    "\n",
    "    return dict(\n",
    "        name=name,\n",
    "        ks_values=dvals,\n",
    "        leakage_points=leaks,\n",
    "        fixed_count=fixed.shape[0],\n",
    "        random_count=random.shape[0],\n",
    "        window=(qs, qe),\n",
    "        csv_ks=ks_csv,\n",
    "        pdf_ks=ks_pdf if save_plots else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c253f8-026b-47fe-9b64-9b36ae5d9352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paths\n",
    "traces_path = \"/Users/andrew/Desktop/thesis/only-traces/capture_traces/unprotected\"\n",
    "inputs_file = \"/Users/andrew/Desktop/thesis/only-traces/capture_traces/unprotected/inputs.txt\"\n",
    "\n",
    "# full-window TVLA (1..24430)\n",
    "res_tvla = run_tvla_pipeline(\n",
    "    name=\"unprotected_new_nn\",\n",
    "    traces_path=traces_path,\n",
    "    inputs_file=inputs_file,\n",
    "    v=0.5,\n",
    "    qs=1,\n",
    "    qe=24430,\n",
    "    tvla_threshold=4.5,\n",
    "    out_dir=\"./out_tvla\"\n",
    ")\n",
    "\n",
    "# optional KSLA on same split (set threshold if you want a line; or compute quantile externally)\n",
    "res_ksla = run_ksla_pipeline(\n",
    "    name=\"unprotected_new_nn\",\n",
    "    traces_path=traces_path,\n",
    "    inputs_file=inputs_file,\n",
    "    v=0.5,\n",
    "    qs=1,\n",
    "    qe=24430,\n",
    "    ks_threshold=0.2,\n",
    "    out_dir=\"./out_tvla\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd6d11-c73c-4f1b-8833-a15a4f3a330a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
