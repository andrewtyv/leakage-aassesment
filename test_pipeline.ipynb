{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefaffb4-fd84-4abb-82b7-7763e07b0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87580d2e-ea05-45c5-a68a-7a86b486f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_traces_sorted(traces_path: str) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Return a list of trace files sorted by their numeric index in 'trace_<idx>.txt'.\n",
    "    Accepts absolute or relative path.\n",
    "    \"\"\"\n",
    "    paths = [Path(p) for p in glob.glob(str(Path(traces_path) / \"trace_*.txt\"))]\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No trace_*.txt files under: {traces_path}\")\n",
    "    # extract numeric index\n",
    "    def idx(p: Path) -> int:\n",
    "        m = re.match(r\"trace_(\\d+)\\.txt$\", p.name)\n",
    "        if not m:\n",
    "            raise ValueError(f\"Bad trace filename: {p.name}\")\n",
    "        return int(m.group(1))\n",
    "    paths.sort(key=idx)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fca96-079d-497d-ac71-fef2d79a1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inputs_matrix(inputs_file: str, ncols: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load 'inputs.txt' as numeric matrix with ncols columns (default 7: V1..V7).\n",
    "    Assumes space-separated values with no header.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(inputs_file, sep=r\"\\s+\", header=None, engine=\"python\")\n",
    "    if df.shape[1] != ncols:\n",
    "        raise ValueError(f\"Expected {ncols} columns, got {df.shape[1]} in {inputs_file}\")\n",
    "    return df.values  # (N, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea2c29-d1b3-4c8c-88ab-02273e263920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_traces_matrix(traces_path: str) -> Tuple[np.ndarray, List[int]]:\n",
    "    \"\"\"\n",
    "    Read all traces into a matrix of shape (N, S).\n",
    "    Returns (traces, idx_list), where idx_list contains the numeric file indices (0-based).\n",
    "    \"\"\"\n",
    "    files = list_traces_sorted(traces_path)\n",
    "    idx_list = []\n",
    "    rows = []\n",
    "    for f in files:\n",
    "        m = re.match(r\"trace_(\\d+)\\.txt$\", f.name)\n",
    "        idx_list.append(int(m.group(1)))\n",
    "        # robust read: allow whitespace/newlines; each file is 1D vector\n",
    "        data = np.loadtxt(f, dtype=float)\n",
    "        rows.append(np.atleast_1d(data))\n",
    "    # sanity: ensure equal length (pad/raise if needed)\n",
    "    lens = [r.size for r in rows]\n",
    "    if len(set(lens)) != 1:\n",
    "        raise ValueError(f\"Traces have varying lengths: {set(lens)}\")\n",
    "    X = np.vstack(rows)  # (N, S)\n",
    "    return X, idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa412066-517f-40cb-9b81-f84afcc6cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_inputs_to_traces(inputs: np.ndarray, idx_list: List[int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Align inputs rows to trace files by 0-based index in filename.\n",
    "    \"\"\"\n",
    "    max_idx = max(idx_list)\n",
    "    if max_idx >= inputs.shape[0]:\n",
    "        raise IndexError(\n",
    "            f\"inputs has only {inputs.shape[0]} rows, but file index {max_idx} appears.\"\n",
    "        )\n",
    "    aligned = inputs[np.array(idx_list), :]  # pick rows by 0-based indices\n",
    "    return aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3e213-1625-4549-8665-52679819b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_traces(X: np.ndarray, qs: int, qe: Optional[int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Slice columns [qs:qe] (1-based inclusive in your R; here we accept 1-based for familiarity).\n",
    "    If qe is None, use full width. Returns a copy.\n",
    "    \"\"\"\n",
    "    S = X.shape[1]\n",
    "    if qe is None:\n",
    "        qe = S\n",
    "    # convert to 0-based python slicing\n",
    "    qs0 = max(0, qs - 1)\n",
    "    qe0 = min(S, qe)  # slice end is exclusive in Python, so keep as is\n",
    "    if qs0 >= qe0:\n",
    "        raise ValueError(f\"Bad window [{qs}, {qe}] for S={S}\")\n",
    "    return X[:, qs0:qe0].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde97e4-68b4-465c-9844-f4ca570d62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fixed_random(\n",
    "    inputs_aligned: np.ndarray,\n",
    "    v: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Return (fixed_rows, random_rows) as arrays of row indices based on V1 == v criterion.\n",
    "    \"\"\"\n",
    "    V1 = inputs_aligned[:, 0]\n",
    "    fixed_rows = np.where(V1 == v)[0]\n",
    "    random_rows = np.where(V1 != v)[0]\n",
    "    if fixed_rows.size == 0 or random_rows.size == 0:\n",
    "        raise ValueError(\"One of the groups is empty (fixed_rows or random_rows).\")\n",
    "    return fixed_rows, random_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb9788-29dd-4132-8af5-6e3e8ce95adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_groups(\n",
    "    X: np.ndarray, fixed_rows: np.ndarray, random_rows: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build group matrices (fixed, random) by selecting corresponding rows.\n",
    "    \"\"\"\n",
    "    fixed = X[fixed_rows, :]\n",
    "    random = X[random_rows, :]\n",
    "    return fixed, random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb3958-a59c-4aa7-ada2-fff97e53da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tvla_welch_tcurve(fixed: np.ndarray, random: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute per-sample Welch's t-statistic (column-wise),\n",
    "    using manual formula instead of scipy.\n",
    "    Returns (S,) array of t-values.\n",
    "    \"\"\"\n",
    "    if fixed.shape[1] != random.shape[1]:\n",
    "        raise ValueError(\"fixed and random must have same number of columns\")\n",
    "\n",
    "    nx, S = fixed.shape\n",
    "    ny, _ = random.shape\n",
    "\n",
    "    # means per column\n",
    "    mean_x = fixed.mean(axis=0)\n",
    "    mean_y = random.mean(axis=0)\n",
    "\n",
    "    # unbiased variances per column\n",
    "    var_x = fixed.var(axis=0, ddof=1)\n",
    "    var_y = random.var(axis=0, ddof=1)\n",
    "\n",
    "    # Welch t formula\n",
    "    denom = np.sqrt(var_x / nx + var_y / ny)\n",
    "    # avoid division by zero\n",
    "    denom[denom == 0] = np.nan\n",
    "\n",
    "    tvals = (mean_x - mean_y) / denom\n",
    "    return tvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3473320-18ac-4b4d-855e-5de1b796787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tvla_curve(\n",
    "    tvals: np.ndarray,\n",
    "    qs: int,\n",
    "    qe: int,\n",
    "    threshold: float = 4.5,\n",
    "    title: str = \"TVLA (Welch)\",\n",
    "    figsize: Tuple[float, float] = (10, 4),\n",
    "    out_pdf: Optional[str] = None,\n",
    ") -> None:\n",
    "    x = np.arange(qs, qs + tvals.size)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(x, tvals, lw=1.3)\n",
    "    plt.axhline(+threshold, color=\"r\", ls=\"--\")\n",
    "    plt.axhline(-threshold, color=\"r\", ls=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(f\"Sample index ({qs}-{qe})\")\n",
    "    plt.ylabel(\"t-value\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if out_pdf:\n",
    "        plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e672e-98df-45f2-9014-2d30cdd9939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_power_curve_TVLA(\n",
    "    m_values: np.ndarray,\n",
    "    max_abs_t: np.ndarray,\n",
    "    title: str = \"TVLA max-|t| vs traces-per-group\",\n",
    "    figsize: Tuple[float, float] = (10, 4),\n",
    "    out_pdf: Optional[str] = None,\n",
    ") -> None:\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(m_values, max_abs_t, width=max(1, int(len(m_values) / 40)))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Traces per group (m)\")\n",
    "    plt.ylabel(\"Max |t| across window\")\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    if out_pdf:\n",
    "        plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2458b46-5992-4abe-9b40-cc021368b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvla_power_curve(\n",
    "    fixed: np.ndarray,\n",
    "    random: np.ndarray,\n",
    "    min_fixed: int = 10,\n",
    "    max_steps: int = 100,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    For m from min_fixed..m_max (subsampled to <= max_steps points):\n",
    "    - take the FIRST m traces from each group (as in your R code) and compute t-curve\n",
    "      (deterministic), OR you can randomize selection if you want Monte Carlo flavour.\n",
    "    - record max |t| in the window.\n",
    "    Returns: (m_values, max_abs_t_values)\n",
    "    \"\"\"\n",
    "    n_fixed, S = fixed.shape\n",
    "    n_random, _ = random.shape\n",
    "    m_max = min(n_fixed, n_random)\n",
    "    if m_max < min_fixed:\n",
    "        raise ValueError(\"Not enough traces per group for the power curve.\")\n",
    "\n",
    "    # choose up to max_steps evenly spaced m values (integers, unique)\n",
    "    steps = min(max_steps, m_max - min_fixed + 1)\n",
    "    m_vals = np.unique(np.round(np.linspace(min_fixed, m_max, steps)).astype(int))\n",
    "\n",
    "    max_abs_t = np.empty_like(m_vals, dtype=float)\n",
    "    for j, m in enumerate(m_vals):\n",
    "        # deterministic prefix selection (to match your R approach):\n",
    "        t_m = tvla_welch_tcurve(fixed[:m, :], random[:m, :])\n",
    "        max_abs_t[j] = np.nanmax(np.abs(t_m))\n",
    "    return m_vals, max_abs_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7e3e9-438b-4f4a-8fcf-222edc2ca5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_power_curve_line_TVLA(m_vals: np.ndarray, max_abs_t: np.ndarray, title: str, out_pdf: str):\n",
    "    \"\"\"\n",
    "    Line plot (not histogram): x = traces-per-group (m), y = max |t|.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(9, 4.8))\n",
    "    plt.plot(m_vals, max_abs_t, marker=\"o\", linewidth=1.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Number of traces per group (m)\")\n",
    "    plt.ylabel(\"Max |t| in window\")\n",
    "    plt.grid(True, which=\"both\", linestyle=\":\", linewidth=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f08cf2-1374-492b-bf9f-5e4befd265f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_tvla_pipeline(\n",
    "    name: str,\n",
    "    traces_path: str,\n",
    "    inputs_file: str,\n",
    "    v: float = 0.5,\n",
    "    qs: int = 1,\n",
    "    qe: Optional[int] = None,\n",
    "    tvla_threshold: float = 4.5,\n",
    "    min_fixed: int = 10,\n",
    "    out_dir: str = \"./out_tvla\",\n",
    "    save_plots: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    End-to-end TVLA pipeline:\n",
    "      1) load traces+inputs, align by numeric index\n",
    "      2) select window [qs:qe]\n",
    "      3) split (V1 == v)\n",
    "      4) compute Welch t-curve (manual implementation elsewhere)\n",
    "      5) save plot/CSV (filenames include number of threshold exceedances)\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) load / align\n",
    "    X, idx_list = load_traces_matrix(traces_path)\n",
    "    inputs = load_inputs_matrix(inputs_file, ncols=7)\n",
    "    inputs_aligned = align_inputs_to_traces(inputs, idx_list)\n",
    "\n",
    "    # 2) window\n",
    "    Xw = window_traces(X, qs, qe)\n",
    "    S = Xw.shape[1]\n",
    "    if qe is None:  # for labeling\n",
    "        qe = qs + S - 1\n",
    "\n",
    "    # 3) split\n",
    "    fixed_rows, random_rows = split_fixed_random(inputs_aligned, v)\n",
    "    fixed, random = extract_groups(Xw, fixed_rows, random_rows)\n",
    "\n",
    "    # 4) t-curve\n",
    "    tvals = tvla_welch_tcurve(fixed, random)\n",
    "    tvals_clean = np.where(np.isfinite(tvals), tvals, 0.0)\n",
    "\n",
    "    # --- count exceedances before naming files ---\n",
    "    exceed_idx_0based = np.where(np.abs(tvals) > tvla_threshold)[0]\n",
    "    n_exceed = int(exceed_idx_0based.size)\n",
    "\n",
    "    # 5) save CSV (filename includes count)\n",
    "    t_csv = str(Path(out_dir) / f\"tvalues_{name}_exceed{n_exceed}.csv\")\n",
    "    pd.DataFrame({\"sample\": np.arange(qs, qs + S), \"t_value\": tvals}).to_csv(t_csv, index=False)\n",
    "\n",
    "    # 6) plot (filename includes count)\n",
    "    t_pdf = str(Path(out_dir) / f\"tvla_{name}_exceed{n_exceed}.pdf\")\n",
    "    if save_plots:\n",
    "        plot_tvla_curve(\n",
    "            tvals, qs, qe,\n",
    "            threshold=tvla_threshold,\n",
    "            title=f\"TVLA — {name} (exceed={n_exceed})\",\n",
    "            out_pdf=t_pdf\n",
    "        )\n",
    "\n",
    "    # leakage points (1-based sample labeling for return)\n",
    "    leaks_1based = exceed_idx_0based + qs\n",
    "\n",
    "     # 5) POWER CURVE (line, not histogram)\n",
    "    #m_vals, max_abs_t = tvla_power_curve(fixed, random, min_fixed=min_fixed, max_steps=100)\n",
    "    #p_csv = str(Path(out_dir) / f\"tvla_power_curve_{name}.csv\")\n",
    "    #pd.DataFrame({\"traces_per_group\": m_vals, \"max_abs_t\": max_abs_t}).to_csv(p_csv, index=False)\n",
    "\n",
    "    #p_pdf = str(Path(out_dir) / f\"tvla_power_curve_{name}.pdf\")\n",
    "    #if save_plots:\n",
    "     #   plot_power_curve_line_TVLA(m_vals, max_abs_t,\n",
    "      #                        title=f\"TVLA power curve — {name}\",\n",
    "       #                       out_pdf=p_pdf)\n",
    "\n",
    "\n",
    "    return dict(\n",
    "        name=name,\n",
    "        t_values=tvals,\n",
    "        leakage_points=leaks_1based,\n",
    "        fixed_count=fixed.shape[0],\n",
    "        random_count=random.shape[0],\n",
    "        window=(qs, qe),\n",
    "        csv_tvalues=t_csv,\n",
    "        pdf_tvalues=t_pdf if save_plots else None,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d074c-33bc-41ce-ae6d-79fe370540f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tvla = run_tvla_pipeline(\n",
    "    name=\"protected_1_neuron_jitters\",\n",
    "    traces_path=\"/Users/andrew/Desktop/thesis/only-traces/capture_traces/protected1stneuron_jitters_fixed_vs_fixed\",\n",
    "    inputs_file=\"/Users/andrew/Desktop/thesis/only-traces/capture_traces/protected1stneuron_jitters_fixed_vs_fixed/inputs.txt\",\n",
    "    v=2,\n",
    "    qs=0,\n",
    "    qe=24430,\n",
    "    tvla_threshold=4.5,\n",
    "    out_dir=\"/Users/andrew/Desktop/results_tvla/protected1stneuron_jitters_fixedvsfixed\"\n",
    ")\n",
    "run_ksla_pipeline(\n",
    "    name=\"protected_1_neuron_jitters_KSLA_0.1\",\n",
    "    traces_path=\"/Users/andrew/Desktop/thesis/only-traces/capture_traces/protected1stneuron_jitters_fixed_vs_fixed\",\n",
    "    inputs_file=\"/Users/andrew/Desktop/thesis/only-traces/capture_traces/protected1stneuron_jitters_fixed_vs_fixed/inputs.txt\",\n",
    "    v=2, qs=0, qe=24430,\n",
    "    ksla_threshold=0.1,\n",
    "    out_dir=\"/Users/andrew/Desktop/results_tvla/protected1stneuron_jitters_fixed_vs_fixed_KSLA\",\n",
    "    pc_qs=1, pc_qe=3000,    \n",
    "    pc_win_size=20, pc_step=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e6924-56ed-4915-8019-607ceb454172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- KSLA core ----------\n",
    "def _ks_D_one(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Manual two-sample Kolmogorov–Smirnov D in [0,1].\n",
    "    \"\"\"\n",
    "    a = np.asarray(a, dtype=float).ravel()\n",
    "    b = np.asarray(b, dtype=float).ravel()\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return np.nan\n",
    "    a_sorted = np.sort(a)\n",
    "    b_sorted = np.sort(b)\n",
    "    z = np.sort(np.concatenate([a_sorted, b_sorted]))\n",
    "    Fa = np.searchsorted(a_sorted, z, side=\"right\") / a_sorted.size\n",
    "    Fb = np.searchsorted(b_sorted, z, side=\"right\") / b_sorted.size\n",
    "    return float(np.max(np.abs(Fa - Fb)))\n",
    "\n",
    "def ksla_stat(fixed: np.ndarray, random: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Column-wise KS D statistics. Returns (S,) in [0,1] (NaN if empty group).\n",
    "    \"\"\"\n",
    "    if fixed.shape[1] != random.shape[1]:\n",
    "        raise ValueError(\"fixed and random must have same number of columns\")\n",
    "    S = fixed.shape[1]\n",
    "    D = np.empty(S, dtype=float)\n",
    "    for i in range(S):\n",
    "        D[i] = _ks_D_one(fixed[:, i], random[:, i])\n",
    "    # strong safety:\n",
    "    D = np.clip(D, 0.0, 1.0)\n",
    "    return D\n",
    "\n",
    "# ---------- Plot helpers ----------\n",
    "def plot_ksla_curve(\n",
    "    Dvals: np.ndarray,\n",
    "    qs: int,\n",
    "    qe: int,\n",
    "    threshold: float = 0.2,\n",
    "    title: str = \"KSLA (K-S D)\",\n",
    "    figsize=(10, 4.2),\n",
    "    out_pdf: Optional[str] = None,\n",
    ") -> None:\n",
    "    x = np.arange(qs, qs + Dvals.size)\n",
    "    y = np.where(np.isfinite(Dvals), Dvals, 0.0)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(x, y, lw=1.4)\n",
    "    plt.axhline(threshold, color=\"r\", ls=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(f\"Sample index ({qs}-{qe})\")\n",
    "    plt.ylabel(\"KS D\")\n",
    "    plt.grid(True, ls=\":\", alpha=0.6)\n",
    "    if out_pdf:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def plot_power_curve_line_KSLA(m_vals: np.ndarray, y_vals: np.ndarray, title: str, out_pdf: str):\n",
    "    plt.figure(figsize=(9, 4.8))\n",
    "    plt.plot(m_vals, y_vals, marker=\"o\", lw=1.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Number of traces per group (m)\")\n",
    "    plt.ylabel(\"Max KS D in window\")\n",
    "    plt.grid(True, ls=\":\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# ---------- KSLA power curve ----------\n",
    "def ksla_power_curve(\n",
    "    fixed: np.ndarray,\n",
    "    random: np.ndarray,\n",
    "    min_fixed: int = 10,\n",
    "    max_steps: int = 100,\n",
    "    col_slice: Optional[slice] = None,  # fixed subwindow of columns\n",
    "    win_size: Optional[int] = None,     # sliding window length (over columns)\n",
    "    win_step: int = 256,                # sliding step\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    For m in [min_fixed..m_max] (subsampled to <= max_steps points):\n",
    "      - take first m traces from each group,\n",
    "      - compute column-wise KS D,\n",
    "      - record the maximum D either:\n",
    "          * inside col_slice, or\n",
    "          * over all sliding windows of length win_size (step=win_step), or\n",
    "          * over the full range if both are None.\n",
    "    Returns: (m_values, max_D_values)\n",
    "    \"\"\"\n",
    "    n_fixed, S = fixed.shape\n",
    "    n_random, _ = random.shape\n",
    "    m_max = min(n_fixed, n_random)\n",
    "    if m_max < min_fixed:\n",
    "        raise ValueError(\"Not enough traces per group for the power curve.\")\n",
    "    steps = min(max_steps, m_max - min_fixed + 1)\n",
    "    m_vals = np.unique(np.round(np.linspace(min_fixed, m_max, steps)).astype(int))\n",
    "\n",
    "    def max_in_cols(D_curve: np.ndarray) -> float:\n",
    "        if col_slice is not None:\n",
    "            return float(np.nanmax(D_curve[col_slice]))\n",
    "        if win_size is not None:\n",
    "            if win_size > S:\n",
    "                raise ValueError(\"win_size exceeds number of samples\")\n",
    "            best = 0.0\n",
    "            for start in range(0, S - win_size + 1, max(1, win_step)):\n",
    "                end = start + win_size\n",
    "                v = float(np.nanmax(D_curve[start:end]))\n",
    "                if v > best:\n",
    "                    best = v\n",
    "            return best\n",
    "        return float(np.nanmax(D_curve))\n",
    "\n",
    "    max_D = np.empty_like(m_vals, dtype=float)\n",
    "    for j, m in enumerate(m_vals):\n",
    "        D_m = ksla_stat(fixed[:m, :], random[:m, :])\n",
    "        max_D[j] = max_in_cols(D_m)\n",
    "    return m_vals, max_D\n",
    "\n",
    "# ---------- End-to-end KSLA pipeline ----------\n",
    "def run_ksla_pipeline(\n",
    "    name: str,\n",
    "    traces_path: str,\n",
    "    inputs_file: str,\n",
    "    v: float = 0.5,\n",
    "    qs: int = 1,\n",
    "    qe: Optional[int] = None,\n",
    "    ksla_threshold: float = 0.2,\n",
    "    min_fixed: int = 10,\n",
    "    out_dir: str = \"./out_ksla\",\n",
    "    save_plots: bool = True,\n",
    "    # power-curve windowing:\n",
    "    pc_qs: Optional[int] = None,       # absolute sample indices (subset for power curve)\n",
    "    pc_qe: Optional[int] = None,\n",
    "    pc_win_size: Optional[int] = None, # sliding window length over chosen subset\n",
    "    pc_step: int = 256,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    1) load traces+inputs and align (uses your existing helpers)\n",
    "    2) window [qs:qe]\n",
    "    3) split fixed/random (V1 == v)\n",
    "    4) compute KSLA curve, save CSV/PDF (filenames include exceed count)\n",
    "    5) compute KSLA power curve (max D vs m) with optional subwindow/sliding window, save CSV/PDF\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- your loaders/splitters (assumed available) ---\n",
    "    X, idx_list = load_traces_matrix(traces_path)\n",
    "    inputs = load_inputs_matrix(inputs_file, ncols=7)\n",
    "    inputs_aligned = align_inputs_to_traces(inputs, idx_list)\n",
    "\n",
    "    # window\n",
    "    Xw = window_traces(X, qs, qe)\n",
    "    S = Xw.shape[1]\n",
    "    if qe is None:\n",
    "        qe = qs + S - 1\n",
    "\n",
    "    # split & extract groups\n",
    "    fixed_rows, random_rows = split_fixed_random(inputs_aligned, v)\n",
    "    fixed, random = extract_groups(Xw, fixed_rows, random_rows)  # shapes: (Nf, S), (Nr, S)\n",
    "\n",
    "    # ---- KSLA curve ----\n",
    "    Dvals = ksla_stat(fixed, random)\n",
    "    exceed_idx_0b = np.where(Dvals > ksla_threshold)[0]\n",
    "    n_exceed = int(exceed_idx_0b.size)\n",
    "\n",
    "    # CSV\n",
    "    D_csv = str(Path(out_dir) / f\"ksla_Dvalues_{name}_exceed{n_exceed}.csv\")\n",
    "    pd.DataFrame({\"sample\": np.arange(qs, qs + S), \"D\": Dvals}).to_csv(D_csv, index=False)\n",
    "\n",
    "    # PDF\n",
    "    D_pdf = str(Path(out_dir) / f\"ksla_{name}_exceed{n_exceed}.pdf\")\n",
    "    if save_plots:\n",
    "        plot_ksla_curve(Dvals, qs, qe, threshold=ksla_threshold,\n",
    "                        title=f\"KSLA — {name} (exceed={n_exceed})\",\n",
    "                        out_pdf=D_pdf)\n",
    "\n",
    "    # ---- KSLA power curve ----\n",
    "    # allow subrange [pc_qs:pc_qe] AND sliding window inside it\n",
    "    subF, subR = fixed, random\n",
    "    sub_qs, sub_qe = qs, qe\n",
    "    if pc_qs is not None or pc_qe is not None:\n",
    "        a = pc_qs if pc_qs is not None else qs\n",
    "        b = pc_qe if pc_qe is not None else qe\n",
    "        a = max(a, qs); b = min(b, qe)\n",
    "        if a > b:\n",
    "            raise ValueError(\"power-curve window is empty\")\n",
    "        start = a - qs\n",
    "        end = b - qs + 1\n",
    "        subF = fixed[:, start:end]\n",
    "        subR = random[:, start:end]\n",
    "        sub_qs, sub_qe = a, b\n",
    "\n",
    "    m_vals, max_D = ksla_power_curve(\n",
    "        subF, subR,\n",
    "        min_fixed=min_fixed, max_steps=100,\n",
    "        col_slice=None,               # we already cut subrange above\n",
    "        win_size=pc_win_size, win_step=pc_step\n",
    "    )\n",
    "\n",
    "    # CSV for power curve\n",
    "    p_csv = str(Path(out_dir) / f\"ksla_power_curve_{name}.csv\")\n",
    "    pd.DataFrame({\"traces_per_group\": m_vals, \"max_D\": max_D}).to_csv(p_csv, index=False)\n",
    "\n",
    "    # PDF for power curve (line)\n",
    "    subtitle = f\" window={sub_qs}-{sub_qe}\"\n",
    "    if pc_win_size is not None:\n",
    "        subtitle += f\", sliding L={pc_win_size}, step={pc_step}\"\n",
    "    p_pdf = str(Path(out_dir) / f\"ksla_power_curve_{name}.pdf\")\n",
    "    if save_plots:\n",
    "        plot_power_curve_line_KSLA(m_vals, max_D, f\"KSLA power curve — {name}{subtitle}\", p_pdf)\n",
    "\n",
    "    # return summary (optional)\n",
    "    return dict(\n",
    "        name=name,\n",
    "        ksla_threshold=ksla_threshold,\n",
    "        D_values=Dvals,\n",
    "        exceed_idx=(exceed_idx_0b + qs),\n",
    "        max_D=float(np.nanmax(Dvals)),\n",
    "        max_D_at=int(np.nanargmax(Dvals) + qs),\n",
    "        csv_Dvalues=D_csv,\n",
    "        pdf_Dcurve=D_pdf if save_plots else None,\n",
    "        power_curve_m=m_vals,\n",
    "        power_curve_max_D=max_D,\n",
    "        csv_power=p_csv,\n",
    "        pdf_power=p_pdf if save_plots else None,\n",
    "        power_window=dict(range=(sub_qs, sub_qe),\n",
    "                          sliding=None if pc_win_size is None else dict(L=pc_win_size, step=pc_step)),\n",
    "        counts=dict(fixed=fixed.shape[0], random=random.shape[0], samples=S),\n",
    "        main_window=(qs, qe),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b94058-52e1-461b-aa52-840b4dfb41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _yuen_g(n: int, gamma: float) -> int:\n",
    "    if not (0 <= gamma < 0.5):\n",
    "        raise ValueError(\"gamma must be in [0, 0.5)\")\n",
    "    return int(np.floor(gamma * n))\n",
    "\n",
    "def _trim_vec(x: np.ndarray, g: int) -> np.ndarray:\n",
    "    xs = np.sort(np.asarray(x, dtype=float))\n",
    "    if g <= 0:\n",
    "        return xs\n",
    "    if 2*g >= xs.size:\n",
    "        raise ValueError(\"Too much trimming for given sample size.\")\n",
    "    return xs[g: xs.size - g]\n",
    "\n",
    "def _winsorize_vec(x: np.ndarray, g: int) -> np.ndarray:\n",
    "    xs = np.sort(np.asarray(x, dtype=float))\n",
    "    n = xs.size\n",
    "    if g <= 0:\n",
    "        return xs\n",
    "    if 2*g >= n:\n",
    "        raise ValueError(\"Too much winsorization for given sample size.\")\n",
    "    lower = xs[g]\n",
    "    upper = xs[n - g - 1]\n",
    "    xs[:g] = lower\n",
    "    xs[n - g:] = upper\n",
    "    return xs\n",
    "\n",
    "def _trimmed_mean(x: np.ndarray, gamma: float = 0.2) -> float:\n",
    "    g = _yuen_g(x.size, gamma)\n",
    "    return float(np.mean(_trim_vec(x, g)))\n",
    "\n",
    "def _winsorized_var(x: np.ndarray, gamma: float = 0.2) -> float:\n",
    "    g = _yuen_g(x.size, gamma)\n",
    "    wx = _winsorize_vec(x, g)\n",
    "    return float(np.var(wx, ddof=1))  # unbiased sample variance\n",
    "\n",
    "def yuen_t_two_sample(x: np.ndarray, y: np.ndarray, gamma: float = 0.2):\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "    n1, n2 = x.size, y.size\n",
    "    g1, g2 = _yuen_g(n1, gamma), _yuen_g(n2, gamma)\n",
    "    h1, h2 = n1 - 2*g1, n2 - 2*g2\n",
    "    if h1 < 2 or h2 < 2:\n",
    "        raise ValueError(\"Too much trimming for given sample sizes.\")\n",
    "\n",
    "    x_tmean = _trimmed_mean(x, gamma)\n",
    "    y_tmean = _trimmed_mean(y, gamma)\n",
    "    s2w1 = _winsorized_var(x, gamma)\n",
    "    s2w2 = _winsorized_var(y, gamma)\n",
    "\n",
    "    q1 = ((n1 - 1) * s2w1) / (h1 * (h1 - 1))\n",
    "    q2 = ((n2 - 1) * s2w2) / (h2 * (h2 - 1))\n",
    "    se2 = q1 + q2\n",
    "    tval = (x_tmean - y_tmean) / np.sqrt(se2)\n",
    "\n",
    "    df = (se2**2) / ((q1**2) / (h1 - 1) + (q2**2) / (h2 - 1))\n",
    "    return float(tval), float(df)\n",
    "\n",
    "def yuen_tcurve(fixed: np.ndarray, random: np.ndarray, gamma: float = 0.2) -> np.ndarray:\n",
    "    \"\"\"t-vals through all samples\"\"\"\n",
    "    fixed = np.asarray(fixed, dtype=float)\n",
    "    random = np.asarray(random, dtype=float)\n",
    "    if fixed.shape[1] != random.shape[1]:\n",
    "        raise ValueError(\"fixed and random must have the same number of columns.\")\n",
    "    T = fixed.shape[1]\n",
    "    tvals = np.empty(T, dtype=float)\n",
    "    for j in range(T):\n",
    "        tvals[j], _ = yuen_t_two_sample(fixed[:, j], random[:, j], gamma=gamma)\n",
    "    return tvals\n",
    "\n",
    "def plot_yuen_curve(\n",
    "    tvals: np.ndarray,\n",
    "    qs: int,\n",
    "    qe: int,\n",
    "    threshold: float,\n",
    "    title: str,\n",
    "    out_pdf: Optional[str] = None,\n",
    "):\n",
    "    S = tvals.size\n",
    "    x = np.arange(qs, qs + S)  \n",
    "    plt.figure()\n",
    "    plt.plot(x, tvals, linewidth=1.2)\n",
    "    plt.axhline(0.0, linestyle=\"--\", linewidth=0.8)\n",
    "    plt.axhline(+threshold, linestyle=\":\", linewidth=0.8)\n",
    "    plt.axhline(-threshold, linestyle=\":\", linewidth=0.8)\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"t-value (Yuen, trimmed mean)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if out_pdf:\n",
    "        plt.savefig(out_pdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "# ===== End-to-end =============================================\n",
    "def run_yuen_pipeline(\n",
    "    name: str,\n",
    "    traces_path: str,\n",
    "    inputs_file: str,\n",
    "    v: float = 0.5,\n",
    "    qs: int = 1,\n",
    "    qe: Optional[int] = None,\n",
    "    yuen_threshold: float = 4.5,\n",
    "    gamma: float = 0.2,\n",
    "    out_dir: str = \"./out_yuen\",\n",
    "    save_plots: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    End-to-end Yuen pipeline (аналогічно твоєму TVLA-пайплайну, без power curve):\n",
    "      1) load traces+inputs, align by numeric index\n",
    "      2) select window [qs:qe] (1-based labeling)\n",
    "      3) split (V1 == v)\n",
    "      4) compute Yuen trimmed-mean t-curve (NumPy-only)\n",
    "      5) save plot/CSV (імена включають кількість перевищень порога)\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) load / align\n",
    "    X, idx_list = load_traces_matrix(traces_path)\n",
    "    inputs = load_inputs_matrix(inputs_file, ncols=7)\n",
    "    inputs_aligned = align_inputs_to_traces(inputs, idx_list) \n",
    "\n",
    "    # 2) window\n",
    "    Xw = window_traces(X, qs, qe)  \n",
    "    S = Xw.shape[1]\n",
    "    if qe is None: \n",
    "        qe = qs + S - 1\n",
    "\n",
    "    # 3) split\n",
    "    fixed_rows, random_rows = split_fixed_random(inputs_aligned, v) \n",
    "    fixed, random = extract_groups(Xw, fixed_rows, random_rows)      \n",
    "\n",
    "    # 4) Yuen t-curve\n",
    "    tvals = yuen_tcurve(fixed, random, gamma=gamma)\n",
    "    tvals_clean = np.where(np.isfinite(tvals), tvals, 0.0)\n",
    "\n",
    "    # --- count exceedances before naming files ---\n",
    "    exceed_idx_0based = np.where(np.abs(tvals_clean) > yuen_threshold)[0]\n",
    "    n_exceed = int(exceed_idx_0based.size)\n",
    "\n",
    "    # 5) save CSV (filename includes count)\n",
    "    t_csv = str(Path(out_dir) / f\"yuen_tvalues_{name}_exceed{n_exceed}.csv\")\n",
    "    pd.DataFrame({\"sample\": np.arange(qs, qs + S), \"t_value\": tvals}).to_csv(t_csv, index=False)\n",
    "\n",
    "    # 6) plot PDF (filename includes count)\n",
    "    t_pdf = str(Path(out_dir) / f\"yuen_{name}_exceed{n_exceed}.pdf\")\n",
    "    if save_plots:\n",
    "        plot_yuen_curve(\n",
    "            tvals_clean, qs, qe,\n",
    "            threshold=yuen_threshold,\n",
    "            title=f\"Yuen (trim={gamma}) — {name} (exceed={n_exceed})\",\n",
    "            out_pdf=t_pdf\n",
    "        )\n",
    "\n",
    "    # leakage points (1-based sample labeling for return)\n",
    "    leaks_1based = exceed_idx_0based + qs\n",
    "\n",
    "    return dict(\n",
    "        name=name,\n",
    "        t_values=tvals,\n",
    "        leakage_points=leaks_1based,\n",
    "        fixed_count=fixed.shape[0],\n",
    "        random_count=random.shape[0],\n",
    "        window=(qs, qe),\n",
    "        csv_tvalues=t_csv,\n",
    "        pdf_tvalues=t_pdf if save_plots else None,\n",
    "        gamma=gamma,\n",
    "        threshold=yuen_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16efeddb-0040-4322-8746-f9241e238ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_yuen_pipeline(\n",
    "    name= \"yuen unprotected1neuron\",\n",
    "    traces_path=\"/Users/andrew/Desktop/thesis/only-traces/capture_traces/unprotected1neuron\",\n",
    "    inputs_file=\"/Users/andrew/Desktop/thesis/only-traces/capture_traces/unprotected1neuron/inputs.txt\",\n",
    "    qs=1, qe=24430,\n",
    "    v=0.5,\n",
    "    gamma=0.2,\n",
    "    yuen_threshold=4.5,\n",
    "    out_dir=\"/Users/andrew/Desktop/results_tvla/yuen_1stneuron_unprot\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb20c9-d9da-4efe-8100-af2dad49ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = \"/Users/andrew/Desktop/thesis/only-traces/capture_traces\"\n",
    "out_root = \"/Users/andrew/Desktop/results_ksla\"\n",
    "\n",
    "for folder_name in sorted(os.listdir(base_dir)):\n",
    "    if folder_name.endswith(\"_data\"):\n",
    "        continue  #\n",
    "\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    out_dir = os.path.join(out_root, f\"ksla_{folder_name}\")\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    traces_path = os.path.join(folder_path)\n",
    "    inputs_file = os.path.join(folder_path, \"inputs.txt\")\n",
    "\n",
    "    if not (os.path.exists(traces_path) and os.path.exists(inputs_file)):\n",
    "        print(f\" skipped {folder_name} — no traces/inputs\")\n",
    "        continue\n",
    "\n",
    "    print(f\" analyze: {folder_name}\")\n",
    "    run_ksla_pipeline(\n",
    "        name=folder_name,\n",
    "        traces_path=traces_path,\n",
    "        inputs_file=inputs_file,\n",
    "        out_dir=out_dir,\n",
    "        save_plots=True,\n",
    "        pc_qs=1000,\n",
    "        pc_qe=4000,\n",
    "        pc_win_size=512,\n",
    "        pc_step=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa84907-1c8b-45e3-a775-f978e8190ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "base_dir = \"/Users/andrew/Desktop/thesis/only-traces/capture_traces\"\n",
    "\n",
    "out_root = \"/Users/andrew/Desktop/results_ytla\"\n",
    "\n",
    "Path(out_root).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for folder_name in sorted(os.listdir(base_dir)):\n",
    "    if folder_name.endswith(\"_data\"):\n",
    "        continue\n",
    "\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    traces_path = os.path.join(folder_path)\n",
    "    inputs_file = os.path.join(folder_path, \"inputs.txt\")\n",
    "\n",
    "    if not (os.path.exists(traces_path) and os.path.exists(inputs_file)):\n",
    "        print(f\" Skip {folder_name} — no traces.txt or inputs.txt\")\n",
    "        continue\n",
    "\n",
    "    out_dir = os.path.join(out_root, f\"yuen_{folder_name}\")\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\" YTLA for: {folder_name}\")\n",
    "    run_yuen_pipeline(\n",
    "        name=folder_name,\n",
    "        traces_path=traces_path,\n",
    "        inputs_file=inputs_file,\n",
    "        v=0.5,\n",
    "        qs=1,\n",
    "        qe=None,              \n",
    "        yuen_threshold=4.5,  \n",
    "        gamma=0.2,            \n",
    "        out_dir=out_dir,\n",
    "        save_plots=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3ccdc-995c-41e1-b84c-18b80e9dfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = \"/Users/andrew/Desktop/thesis/only-traces/capture_traces\"\n",
    "\n",
    "out_root = \"/Users/andrew/Desktop/results_ksla0.1\"\n",
    "\n",
    "for folder_name in sorted(os.listdir(base_dir)):\n",
    "    if folder_name.endswith(\"_data\"):\n",
    "        continue  \n",
    "\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    out_dir = os.path.join(out_root, f\"ksla_{folder_name}\")\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    traces_path = os.path.join(folder_path)\n",
    "    inputs_file = os.path.join(folder_path, \"inputs.txt\")\n",
    "\n",
    "    if not (os.path.exists(traces_path) and os.path.exists(inputs_file)):\n",
    "        print(f\" skipped {folder_name} — no traces/inputs\")\n",
    "        continue\n",
    "\n",
    "    print(f\" analyze: {folder_name}\")\n",
    "    run_ksla_pipeline(\n",
    "        name=folder_name,\n",
    "        traces_path=traces_path,\n",
    "        inputs_file=inputs_file,\n",
    "        out_dir=out_dir,\n",
    "        save_plots=True,\n",
    "        pc_qs=1000,\n",
    "        pc_qe=4000,\n",
    "        pc_win_size=512,\n",
    "        pc_step=256,\n",
    "        ksla_threshold=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381084c5-b5f6-4083-9dcd-656a37ebf3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
